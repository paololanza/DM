{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime \n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['id'] = pd.to_numeric(tweets['id'], errors='coerce')\n",
    "tweets['user_id'] = pd.to_numeric(tweets['user_id'], errors='coerce')\n",
    "tweets['retweet_count'] = pd.to_numeric(tweets['retweet_count'], errors='coerce')\n",
    "tweets['reply_count'] = pd.to_numeric(tweets['reply_count'], errors='coerce')\n",
    "tweets['favorite_count'] = pd.to_numeric(tweets['favorite_count'], errors='coerce')\n",
    "tweets['num_hashtags'] = pd.to_numeric(tweets['num_hashtags'], errors='coerce')\n",
    "tweets['num_mentions'] = pd.to_numeric(tweets['num_mentions'], errors='coerce')\n",
    "tweets['num_urls'] = pd.to_numeric(tweets['num_urls'], errors='coerce')\n",
    "tweets['created_at'] = pd.to_datetime(tweets['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminazione dei valori negativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['retweet_count'] = tweets['retweet_count'].abs()\n",
    "tweets['reply_count'] = tweets['reply_count'].abs()\n",
    "tweets['favorite_count'] = tweets['favorite_count'].abs()\n",
    "tweets['num_hashtags'] = tweets['num_hashtags'].abs()\n",
    "tweets['num_mentions'] = tweets['num_mentions'].abs()\n",
    "tweets['num_urls'] = tweets['num_urls'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminazione dei valori inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.replace(math.inf, math.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage duplicates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and replace duplicated 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tweets.duplicated('id', keep=False)\n",
    "tweets.loc[mask, 'id'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing NaN values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5ceae",
   "metadata": {},
   "source": [
    "### Replace NaN values in 'id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace nan values with a value (-1) that indicates that this information is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[tweets['id'].isna(), 'id'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing NaN values in 'num_hashtags', 'num_urls' and 'num_mentions' by infer from the tweet's text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['infer_hashtags'] = tweets.text.str.count('#')\n",
    "tweets['infer_mentions'] = tweets.text.str.count('@')\n",
    "tweets['infer_urls'] = tweets.text.str.count('http://')\n",
    "\n",
    "tweets['num_hashtags'] = tweets['num_hashtags'].fillna(tweets['infer_hashtags'])\n",
    "tweets['num_mentions'] = tweets['num_mentions'].fillna(tweets['infer_mentions'])\n",
    "tweets['num_urls'] = tweets['num_urls'].fillna(tweets['infer_urls'])\n",
    "\n",
    "tweets.drop(columns=['infer_hashtags', 'infer_mentions', 'infer_urls'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing NaN values with the median of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tweets\n",
    "user_median = t.groupby('user_id', as_index=False).median()\n",
    "user_median.rename(columns={\n",
    "    'retweet_count' : 'retweet_median',\n",
    "    'reply_count' : 'reply_median',\n",
    "    'favorite_count' : 'favorite_median',\n",
    "    'num_hashtags' : 'hashtags_median',\n",
    "    'num_urls' : 'urls_median',\n",
    "    'num_mentions' : 'mentions_median'\n",
    "}, inplace=True)\n",
    "user_median.drop(columns=['id'], inplace=True)\n",
    "tweets = t.merge(user_median, on='user_id')\n",
    "\n",
    "#sostituzione valori\n",
    "tweets['retweet_count'] = tweets['retweet_count'].fillna(tweets['retweet_median'])\n",
    "tweets['reply_count'] = tweets['reply_count'].fillna(tweets['reply_median'])\n",
    "tweets['favorite_count'] = tweets['favorite_count'].fillna(tweets['favorite_median'])\n",
    "tweets['num_hashtags'] = tweets['num_hashtags'].fillna(tweets['hashtags_median'])\n",
    "tweets['num_mentions'] = tweets['num_mentions'].fillna(tweets['mentions_median'])\n",
    "tweets['num_urls'] = tweets['num_urls'].fillna(tweets['urls_median'])\n",
    "\n",
    "tweets.drop(columns=['retweet_median', 'reply_median', 'favorite_median', 'hashtags_median', 'mentions_median', 'urls_median'], \\\n",
    "            inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the remained NaN values with the median of the attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['retweet_count'].replace(math.nan, tweets['retweet_count'].median(), inplace=True)\n",
    "tweets['reply_count'].replace(math.nan, tweets['reply_count'].median(), inplace=True)\n",
    "tweets['favorite_count'].replace(math.nan, tweets['favorite_count'].median(), inplace=True)\n",
    "tweets['num_hashtags'].replace(math.nan, tweets['num_hashtags'].median(), inplace=True)\n",
    "tweets['num_mentions'].replace(math.nan, tweets['num_mentions'].median(), inplace=True)\n",
    "tweets['num_urls'].replace(math.nan, tweets['num_urls'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing invalid 'created_at' with symbolic date (01/01/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[(tweets.created_at < datetime.strptime(\"2006-07-15 00:00:00\", \"%Y-%m-%d %H:%M:%S\")) | \\\n",
    "    (tweets.created_at > datetime.now()),'created_at'] = datetime.strptime(\"2000-01-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[tweets['retweet_count'] > tweets['retweet_count'].quantile(.99), 'retweet_count'] = 0\n",
    "tweets.loc[tweets['reply_count'] > tweets['reply_count'].quantile(.99), 'reply_count'] = 0\n",
    "tweets.loc[tweets['favorite_count'] > tweets['favorite_count'].quantile(.99), 'favorite_count'] = 0\n",
    "tweets.loc[tweets['num_hashtags'] > tweets['num_hashtags'].quantile(.99), 'num_hashtags'] = 0\n",
    "tweets.loc[tweets['num_mentions'] > tweets['num_mentions'].quantile(.99), 'num_mentions'] = 0\n",
    "tweets.loc[tweets['num_urls'] > tweets['num_urls'].quantile(.99), 'num_urls'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of special character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special = '[(|!ยฃ$%&/=?^@#ยง,.;:-_<>รง@)]' # Define special characters\n",
    "tweets['special'] = tweets['text'].str.count(special) # Count them\n",
    "tweets['special'] = tweets['special'].fillna(0)\n",
    "tweets['special'] = tweets['special'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text lenght:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text_lenght'] = tweets['text'].str.len()\n",
    "tweets['text_lenght'] = tweets['text_lenght'].fillna(0)\n",
    "tweets['text_lenght'] = tweets['text_lenght'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a new file '.csv' with all the modify done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('new_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part use the previous modify done to the tweets dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.info()\n",
    "users.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825bdaa",
   "metadata": {},
   "source": [
    "## Column type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['id'] = pd.to_numeric(users['id'], errors='coerce')\n",
    "users['statuses_count'] = pd.to_numeric(users['statuses_count'], errors='coerce')\n",
    "users['created_at'] = pd.to_datetime(users['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec54640f",
   "metadata": {},
   "source": [
    "## Elimination of negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users['statuses_count'] = users['statuses_count'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0673b",
   "metadata": {},
   "source": [
    "## Lang Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65f6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['lang'] = users['lang'].str.lower()\n",
    "users.rename(columns={\n",
    "    'id' : 'user_id',\n",
    "    'created_at' : 'subscribing_date'\n",
    "}, inplace=True)\n",
    "nal = users[(users['lang'] == 'select language...') | (users['lang'] == 'xx-lc')]\n",
    "\n",
    "text_nal = tweets.merge(nal, on='user_id')\n",
    "text_nal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04757d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nal[text_nal['name'] == 'Leanne Arker'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e090f",
   "metadata": {},
   "source": [
    "##### Users without a language are en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a546e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['lang'].replace('select language...', 'en', inplace=True)\n",
    "users['lang'].replace('xx-lc', 'en', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089067b3",
   "metadata": {},
   "source": [
    "## Calculate for each user how many tweets we have in tweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users = users.merge(tweets[['user_id', 'id']].groupby('user_id', as_index=False).count(), on='user_id')\n",
    "users = users.rename(columns={'id' : 'count'})\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0c6d9",
   "metadata": {},
   "source": [
    "## Summing parameters in users (likes received, retweet and reply received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets = tweets.filter(['user_id', 'retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions'], axis=1)\n",
    "new_users = users.merge(new_tweets.groupby('user_id').sum(), on='user_id')\n",
    "new_users = new_users.rename(columns={\n",
    "    'retweet_count' : 'retweet_received',\n",
    "    'reply_count' : 'reply_received',\n",
    "    'favorite_count' : 'favorite_received',\n",
    "    'num_hashtags' : 'hashtag_used',\n",
    "    'num_urls' : 'urls_used',\n",
    "    'num_mentions' : 'mentions_used'}, \n",
    "    errors='raise'\n",
    ")\n",
    "new_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users[\\\n",
    "    (new_users['retweet_received'].isna() == True) |\\\n",
    "    (new_users['reply_received'].isna() == True) |\\\n",
    "    (new_users['favorite_received'].isna() == True) |\\\n",
    "    (new_users['hashtag_used'].isna() == True) |\\\n",
    "    (new_users['urls_used'].isna() == True) |\\\n",
    "    (new_users['mentions_used'].isna() == True)\n",
    "        ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users['reply_received'] = new_users['reply_received'].fillna(-1)\n",
    "new_users['retweet_received'] = new_users['retweet_received'].fillna(-1)\n",
    "new_users['statuses_count'] = new_users['statuses_count'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users['reply_received'] = new_users['reply_received'].astype(int)\n",
    "new_users['retweet_received'] = new_users['retweet_received'].astype(int)\n",
    "new_users['favorite_received'] = new_users['favorite_received'].astype(int)\n",
    "new_users['hashtag_used'] = new_users['hashtag_used'].astype(int)\n",
    "new_users['urls_used'] = new_users['urls_used'].astype(int)\n",
    "new_users['mentions_used'] = new_users['mentions_used'].astype(int)\n",
    "new_users['statuses_count'] = new_users['statuses_count'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02892ab8",
   "metadata": {},
   "source": [
    "## Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users['like/statuses'] = round(new_users['favorite_received'] / new_users['count'], 2)\n",
    "new_users.head(3)\n",
    "users = new_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('new_users.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
