{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime \n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['id'] = pd.to_numeric(tweets['id'], errors='coerce')\n",
    "tweets['user_id'] = pd.to_numeric(tweets['user_id'], errors='coerce')\n",
    "tweets['retweet_count'] = pd.to_numeric(tweets['retweet_count'], errors='coerce')\n",
    "tweets['reply_count'] = pd.to_numeric(tweets['reply_count'], errors='coerce')\n",
    "tweets['favorite_count'] = pd.to_numeric(tweets['favorite_count'], errors='coerce')\n",
    "tweets['num_hashtags'] = pd.to_numeric(tweets['num_hashtags'], errors='coerce')\n",
    "tweets['num_mentions'] = pd.to_numeric(tweets['num_mentions'], errors='coerce')\n",
    "tweets['num_urls'] = pd.to_numeric(tweets['num_urls'], errors='coerce')\n",
    "tweets['created_at'] = pd.to_datetime(tweets['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminazione dei valori negativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['retweet_count'] = tweets['retweet_count'].abs()\n",
    "tweets['reply_count'] = tweets['reply_count'].abs()\n",
    "tweets['favorite_count'] = tweets['favorite_count'].abs()\n",
    "tweets['num_hashtags'] = tweets['num_hashtags'].abs()\n",
    "tweets['num_mentions'] = tweets['num_mentions'].abs()\n",
    "tweets['num_urls'] = tweets['num_urls'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminazione dei valori inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.replace(math.inf, math.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage duplicates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and replace duplicated 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tweets.duplicated('id', keep=False)\n",
    "tweets.loc[mask, 'id'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing NaN values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5ceae",
   "metadata": {},
   "source": [
    "### Replace NaN values in 'id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace nan values with a value (-1) that indicates that this information is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[tweets['id'].isna(), 'id'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing NaN values in 'num_hashtags', 'num_urls' and 'num_mentions' by infer from the tweet's text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['infer_hashtags'] = tweets.text.str.count('#')\n",
    "tweets['infer_mentions'] = tweets.text.str.count('@')\n",
    "tweets['infer_urls'] = tweets.text.str.count('http://')\n",
    "\n",
    "tweets['num_hashtags'] = tweets['num_hashtags'].fillna(tweets['infer_hashtags'])\n",
    "tweets['num_mentions'] = tweets['num_mentions'].fillna(tweets['infer_mentions'])\n",
    "tweets['num_urls'] = tweets['num_urls'].fillna(tweets['infer_urls'])\n",
    "\n",
    "tweets.drop(columns=['infer_hashtags', 'infer_mentions', 'infer_urls'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing NaN values with the median of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tweets\n",
    "user_median = t.groupby('user_id', as_index=False).median()\n",
    "user_median.rename(columns={\n",
    "    'retweet_count' : 'retweet_median',\n",
    "    'reply_count' : 'reply_median',\n",
    "    'favorite_count' : 'favorite_median',\n",
    "    'num_hashtags' : 'hashtags_median',\n",
    "    'num_urls' : 'urls_median',\n",
    "    'num_mentions' : 'mentions_median'\n",
    "}, inplace=True)\n",
    "user_median.drop(columns=['id'], inplace=True)\n",
    "tweets = t.merge(user_median, on='user_id')\n",
    "\n",
    "#sostituzione valori\n",
    "tweets['retweet_count'] = tweets['retweet_count'].fillna(tweets['retweet_median'])\n",
    "tweets['reply_count'] = tweets['reply_count'].fillna(tweets['reply_median'])\n",
    "tweets['favorite_count'] = tweets['favorite_count'].fillna(tweets['favorite_median'])\n",
    "tweets['num_hashtags'] = tweets['num_hashtags'].fillna(tweets['hashtags_median'])\n",
    "tweets['num_mentions'] = tweets['num_mentions'].fillna(tweets['mentions_median'])\n",
    "tweets['num_urls'] = tweets['num_urls'].fillna(tweets['urls_median'])\n",
    "\n",
    "tweets.drop(columns=['retweet_median', 'reply_median', 'favorite_median', 'hashtags_median', 'mentions_median', 'urls_median'], \\\n",
    "            inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the remained NaN values with the median of the attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['retweet_count'].replace(math.nan, tweets['retweet_count'].median(), inplace=True)\n",
    "tweets['reply_count'].replace(math.nan, tweets['reply_count'].median(), inplace=True)\n",
    "tweets['favorite_count'].replace(math.nan, tweets['favorite_count'].median(), inplace=True)\n",
    "tweets['num_hashtags'].replace(math.nan, tweets['num_hashtags'].median(), inplace=True)\n",
    "tweets['num_mentions'].replace(math.nan, tweets['num_mentions'].median(), inplace=True)\n",
    "tweets['num_urls'].replace(math.nan, tweets['num_urls'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing invalid 'created_at' with symbolic date (01/01/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[(tweets.created_at < datetime.strptime(\"2006-07-15 00:00:00\", \"%Y-%m-%d %H:%M:%S\")) | \\\n",
    "    (tweets.created_at > datetime.now()),'created_at'] = datetime.strptime(\"2000-01-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[tweets['retweet_count'] > tweets['retweet_count'].quantile(.99), 'retweet_count'] = 0\n",
    "tweets.loc[tweets['reply_count'] > tweets['reply_count'].quantile(.99), 'reply_count'] = 0\n",
    "tweets.loc[tweets['favorite_count'] > tweets['favorite_count'].quantile(.99), 'favorite_count'] = 0\n",
    "tweets.loc[tweets['num_hashtags'] > tweets['num_hashtags'].quantile(.99), 'num_hashtags'] = 0\n",
    "tweets.loc[tweets['num_mentions'] > tweets['num_mentions'].quantile(.99), 'num_mentions'] = 0\n",
    "tweets.loc[tweets['num_urls'] > tweets['num_urls'].quantile(.99), 'num_urls'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of special character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "special = '[(|!ยฃ$%&/=?^@#ยง,.;:-_<>รง@)]' # Define special characters\n",
    "tweets['special'] = tweets['text'].str.count(special) # Count them\n",
    "tweets['special'] = tweets['special'].fillna(0)\n",
    "tweets['special'] = tweets['special'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text lenght:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text_lenght'] = tweets['text'].str.len()\n",
    "tweets['text_lenght'] = tweets['text_lenght'].fillna(0)\n",
    "tweets['text_lenght'] = tweets['text_lenght'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a new file '.csv' with all the modify done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('new_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part use the previous modify done to the tweets dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['id'] = pd.to_numeric(users['id'], errors='coerce')\n",
    "users['statuses_count'] = pd.to_numeric(users['statuses_count'], errors='coerce')\n",
    "users['created_at'] = pd.to_datetime(users['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
